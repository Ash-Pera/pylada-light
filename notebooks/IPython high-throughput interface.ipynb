{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulating job-folders\n",
    "\n",
    "[IPython](https://ipython.org/) is an ingenious combination of a bash-like terminal with a python shell. It can be used for both bash related affairs such as copying files around creating directories, and for actual python programming. In fact, the\n",
    "two can be combined to create a truly powerfull shell.\n",
    "\n",
    "Alternatively, [Jupyter](http://jupyter.org/) provide an attractive graphical interface for performing data analysis. Or for demonstrating pylada, as in this notebook.\n",
    "\n",
    "Pylada puts these tools to good use by providing a command-line approach to manipulate job-folders (see the relevant notebook for more information), launch actual calculations, and collect the result. When used in conjunction with python plotting libraries, e.g. matplotlib, it can provide rapid turnaround from conceptualization to result analysis.\n",
    "\n",
    "\n",
    "Assuming that pylada is installed, the IPython module can be loaded in ipython/Jupyter with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext pylada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep\n",
    "\n",
    "\n",
    "Pylada's IPython interface revolves around **job-folders**. In order to explore its features, we first need to create job-folders, preferably some which do not involve heavy calculations. The following creates a `dummy.py` file in the current directory. It contains a dummy functional that does very little work. In actual runs, everything `dummy` should be replaced with wrappers to VASP, or Quantum Espresso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting dummy.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile dummy.py\n",
    "def functional(structure, outdir=None, value=False, **kwargs):\n",
    "    \"\"\" A dummy functional \"\"\"\n",
    "    from copy import deepcopy\n",
    "    from pickle import dump\n",
    "    from random import random\n",
    "    from py.path import local\n",
    "\n",
    "    structure = deepcopy(structure)\n",
    "    structure.value = value\n",
    "    outdir = local(outdir)\n",
    "    outdir.ensure(dir=True)\n",
    "    dump((random(), structure, value, functional), outdir.join('OUTCAR').open('wb'))\n",
    "\n",
    "    return Extract(outdir)\n",
    "\n",
    "\n",
    "def Extract(outdir=None):\n",
    "    \"\"\" An extraction function for a dummy functional \"\"\"\n",
    "    from os import getcwd\n",
    "    from collections import namedtuple\n",
    "    from pickle import load\n",
    "    from py.path import local\n",
    "\n",
    "    if outdir == None:\n",
    "        outdir = local()()\n",
    "    Extract = namedtuple('Extract', ['success', 'directory',\n",
    "                                     'structure', 'energy', 'value', 'functional'])\n",
    "    outdir = local(outdir)\n",
    "    if not outdir.check():\n",
    "        return Extract(False, str(outdir), None, None, None, None)\n",
    "    if not outdir.join('OUTCAR').check(file=True):\n",
    "        return Extract(False, str(outdir), None, None, None, None)\n",
    "    with outdir.join('OUTCAR').open('rb') as file:\n",
    "        structure, energy, value, functional = load(file)\n",
    "        return Extract(True, outdir, energy, structure, value, functional)\n",
    "functional.Extract = Extract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook about creating job folders has more details about this functional. For now, let us create a jobfolder with a few jobs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dummy import functional\n",
    "from pylada.jobfolder import JobFolder\n",
    "from pylada.crystal.binary import zinc_blende\n",
    "\n",
    "root = JobFolder()\n",
    "\n",
    "structures = ['diamond', 'diamond/alloy', 'GaAs']\n",
    "stuff = [0, 1, 2]\n",
    "species = [('Si', 'Si'), ('Si', 'Ge'), ('Ga', 'As')]\n",
    "\n",
    "for name, value, species in zip(structures, stuff, species):\n",
    "    job = root / name\n",
    "    job.functional = functional\n",
    "    job.params['value'] = value\n",
    "    job.params['structure'] = zinc_blende()\n",
    "    \n",
    "    for atom, specie in zip(job.structure, species):\n",
    "        atom.type = specie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Loading a job-folder\n",
    "\n",
    "\n",
    "At this point we have job-folder stored in memory in a python variable. If you were to exit ipython, the job-folder would be lost for ever and ever. We can save it do disk with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved job folder to /Users/mdavezac/workspaces/pylada-light/src/pylada-light/notebooks/tmp/dummy.dict.\n"
     ]
    }
   ],
   "source": [
    "%mkdir -p tmp\n",
    "%savefolders tmp/dummy.dict root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next time ipython is entered, the job-folder can be loaded from disk with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded job list from /Users/mdavezac/workspaces/pylada-light/src/pylada-light/notebooks/tmp/dummy.dict.\n"
     ]
    }
   ],
   "source": [
    "%explore tmp/dummy.dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once a folder has been `explored` from disk, `savefolder` can be called\n",
    "without arguments. \n",
    "\n",
    "The percent(%) sign indicates that these commands are ipython\n",
    "[magic-functions](http://ipython.readthedocs.io/en/stable/interactive/magics.html?highlight=magic). To get\n",
    "more information about what Pylada magic functions do, call them with \"--help\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: %explore [-h] [--file | --expression] [TYPE] [JOBFOLDER]\n",
      "\n",
      "Opens a job-folder from file on disk.\n",
      "\n",
      "positional arguments:\n",
      "  TYPE          Optional. Specifies what kind of job folders will be explored.\n",
      "                Can be one of results, errors, all, running. \"results\" are\n",
      "                those job folders which have completed. \"errors\" are those job\n",
      "                folders which are not \"running\" at the time of invokation and\n",
      "                failed somehow. \"all\" means all job folders. By default, the\n",
      "                dictionary is read as it was saved. The modified job-folder is\n",
      "                not saved to disk.\n",
      "  JOBFOLDER     Job-dictionary variable or path to job folder saved to disk.\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help    show this help message and exit\n",
      "  --file        JOBFOLDER is a path to a job-dictionary stored on disk.\n",
      "  --expression  JOBFOLDER is a python expression.\n"
     ]
    }
   ],
   "source": [
    "%explore --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tip**: The current job-folder and the current job-folder path are stored in `pylada.interactive.jobfolder` and `pylada.interactive.jobfolder_path`. In practice, accessing those directly is rarely needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing job-folders\n",
    "\n",
    "\n",
    "The *executable* content of the current job-folder (the one loaded _via_ `%explore`) can be examined with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/GaAs/\n",
      "/diamond/\n",
      "/diamond/alloy/\n"
     ]
    }
   ],
   "source": [
    "%listfolders all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This prints out the *executable* jobs. It can also be used to examine the content of specific subfolders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diamond/alloy "
     ]
    }
   ],
   "source": [
    "%listfolders diamond/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The syntax is the same as for the bash command-line. When given an argument\n",
    "other than \"all\", `%listfolders` list only the matching subfolders, including those which are not\n",
    "executable. In practice, it works like \"ls -d\".\n",
    "\n",
    "Executable job-folders are those that are set to go with a functional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Navigating the job-folders\n",
    "\n",
    "\n",
    "The `%goto` command reproduces the functionality of the \"cd\" unix command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In diamond, but no corresponding directory on disk.\n"
     ]
    }
   ],
   "source": [
    "%goto /diamond"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current job-folder is now `diamond`. Were there a corresponding sub-directory on disk, the current working directory would also be `diamond`. As it is, we have not yet launched the calculations, so no such directory exist. This feature makes it easy to navigate both job-folders and output directories simulteneously.\n",
    "\n",
    "We can check the subfolders contained within `/diamond`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alloy  \n"
     ]
    }
   ],
   "source": [
    "%listfolders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And calling `%goto` without an argument will print out the current location (much like pwd does for directories)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current position in job folder: /diamond/\n",
      "Filename of job-folder:  /Users/mdavezac/workspaces/pylada-light/src/pylada-light/notebooks/tmp/dummy.dict\n"
     ]
    }
   ],
   "source": [
    "%goto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use relative paths, as well as `..` to navigate around the tree structure. Most any path that works for `cd` will work with `%goto` as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current position in job folder: /\n",
      "Filename of job-folder:  /Users/mdavezac/workspaces/pylada-light/src/pylada-light/notebooks/tmp/dummy.dict\n",
      "GaAs  diamond  \n"
     ]
    }
   ],
   "source": [
    "%goto ..\n",
    "%goto\n",
    "%listfolders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining the executable content of a jobfolder\n",
    "\n",
    "It is always possible to change the executable data of a job-folder, whether\n",
    "the functional or its parameters. To do this, we must first navigate to the\n",
    "specific subfolder of interest, and then use the object `jobparams.current`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In alloy, but no corresponding directory on disk.\n"
     ]
    }
   ],
   "source": [
    "%goto /diamond/alloy/\n",
    "assert jobparams.current.functional == functional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters can be accessed either throught the `params` dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['structure', 'value'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobparams.current.params.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or directly as attributes of `jobparams.current`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert jobparams.current.value == 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simultaneously examining/modify parameters for many jobs at a time\n",
    "\n",
    "It is likely that a whole group of calculations will share parameters in common, and that these parameters need be the same. It is possible to examine the computational parameter for any number of jobs simultaneously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  '/GaAs/':          'Zinc-Blende',\n",
       "  '/diamond/':       'Zinc-Blende',\n",
       "  '/diamond/alloy/': 'Zinc-Blende',\n",
       "}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%goto /\n",
    "jobparams.structure.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two things to note here:\n",
    "\n",
    "1. The return is an object that duct-types for dictionaries. The keys are the job-names and the values are the property of interest.\n",
    "1. It is possible to access attributes (here `name`) of attributes (here `structure`) to any degree of nesting. If the parameter of a given job does not contain the nested attribute, then that job is ignored.\n",
    "\n",
    "We can set parameters much the same way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  '/GaAs/':          'hello',\n",
       "  '/diamond/':       'hello',\n",
       "  '/diamond/alloy/': 'hello',\n",
       "}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobparams.structure.name = 'hello'\n",
    "jobparams.structure.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, it is only possible to *modify* existing attributes, as opposed to add new attributes.\n",
    "\n",
    "Finally, it is possible to focus on a specific sub-set of jobfolders. By default the syntax is that of a unix-shell. However, the syntax can be switched to regular exppressions `via` the Pylada parameter `pylada.unix_re`. Only the former syntax is illustrated here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobparams['*/alloy'].structure.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that one only item is left in the dictionary, that item is returned directly. Indeed, there is only one job-folder which corresponds to \"\\*/alloy\". This behavior can be turned on and off using the parameters `jobparams_naked_end` and/or `JobParams.naked_end`. The unix shell-like syntax can be either absolute paths, when preceded with '/', or relative. In that last case, they are relative to the current position in the job-folder, as changed by `%goto`.\n",
    "\n",
    "When the return looks like a dictionary, it behaves like a dictionary. Hence it can be iterated over:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/diamond/ hello\n",
      "/diamond/alloy/ hello\n"
     ]
    }
   ],
   "source": [
    "for key, value in jobparams['diamond/*'].structure.name.items():\n",
    "   print(key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Launching calculations\n",
    "\n",
    "\n",
    "## Turning job-folders on and off\n",
    "\n",
    "Using `jobparams`, it is possible to turn job-folders on and off:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/GaAs/': 'on', '/diamond/': 'on', '/diamond/alloy/': 'on'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%goto /\n",
    "jobparams['diamond/alloy'].onoff = 'on'\n",
    "jobparams.onoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When \"off\", a job-folder is ignored by `jobparams` (and `collect`, described below). Furthermore, it will not be executed. The only way to access it again is to turn it back on. Groups of calculations can be turned on and off\n",
    "using the unix shell-like syntax previously.\n",
    "\n",
    "**WARNING**: You should always save the job-folder after messing with it's on/off status. This is because the computations will re-read the dictionary from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved job folder to /Users/mdavezac/workspaces/pylada-light/src/pylada-light/notebooks/tmp/dummy.dict.\n"
     ]
    }
   ],
   "source": [
    "%savefolders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submitting job-folder calculations\n",
    "\n",
    "Once job-folders are ready, it takes all of one line to launch the calculations:\n",
    "\n",
    "```IPython\n",
    "%launch scattered\n",
    "```\n",
    "\n",
    "This will create one pbs/slurm job per executable job-folder. A number of options are possible to select the number of processors, the account or queue, the walltime, etc. To examine them, do `%launch scattered --help`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: %launch scattered [-h] [--force] [--walltime WALLTIME]\n",
      "                         [--prefix PREFIX] [--nolaunch] [--nbprocs NBPROCS]\n",
      "                         [--ppn PPN] [--account ACCOUNT] [--feature FEATURE]\n",
      "                         [--queue QUEUE] [--debug]\n",
      "                         [FILE [FILE ...]]\n",
      "\n",
      "A separate PBS/slurm script is created for each and every calculation in the\n",
      "job-folder (or dictionaries).\n",
      "\n",
      "positional arguments:\n",
      "  FILE                 Optional path to a job-folder. If not present, the\n",
      "                       currently loaded job-dictionary will be launched.\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help           show this help message and exit\n",
      "  --force              If present, launches all untagged jobs, even those\n",
      "                       which completed successfully.\n",
      "  --walltime WALLTIME  walltime for jobs. Should be in hh:mm:ss format.\n",
      "                       Defaults to 00:30:00.\n",
      "  --prefix PREFIX      Adds prefix to job name.\n",
      "  --nolaunch           Does everything except calling qsub.\n",
      "  --nbprocs NBPROCS    Can be an integer, in which case it specifies the\n",
      "                       number of processes to exectute jobs with. Can also be\n",
      "                       a callable taking a JobFolder as argument and returning\n",
      "                       a integer. Will default to as many procs as there are\n",
      "                       atoms in that particular structure. Defaults to\n",
      "                       something close to the number of atoms in the structure\n",
      "                       (eg good for VASP).\n",
      "  --ppn PPN            Number of processes per node. Defaults to 4.\n",
      "  --account ACCOUNT    Launches jobs on specific account if present.\n",
      "  --feature FEATURE    Launches jobs on specific feature if present.\n",
      "  --queue QUEUE        Launches jobs on specific queue if present.\n",
      "  --debug              launches in interactive queue if present.\n"
     ]
    }
   ],
   "source": [
    "%launch scattered --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most default values should be contained in `pylada.default_pbs`. The number of processors is by default equal to the even number closest to the number of atoms in the structure (apparently, this is a recommended VASP default). The number of processes can be given both as an integer, or as function which takes a job-folder as the only argument, and returns an integer.\n",
    "\n",
    "Other possibilities for lauching jobs can be obtained as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: %launch [-h] {scattered,interactive,asone,single} ...\n",
      "\n",
      "positional arguments:\n",
      "  {scattered,interactive,asone,single}\n",
      "                        Launches one job per untagged calculations\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n"
     ]
    }
   ],
   "source": [
    "%launch --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will be using `%launch interactive` since the jobs are simple and since we cannot be sure that pylada has been configured for PBS, Slurm, or other queueing systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on GaAs/ in /Users/mdavezac/workspaces/pylada-light/src/pylada-light/notebooks/tmp/dummy.dict.\n",
      "Working on diamond/ in /Users/mdavezac/workspaces/pylada-light/src/pylada-light/notebooks/tmp/dummy.dict.\n",
      "Working on diamond/alloy/ in /Users/mdavezac/workspaces/pylada-light/src/pylada-light/notebooks/tmp/dummy.dict.\n"
     ]
    }
   ],
   "source": [
    "%launch interactive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this juncture, we should find that jobs have been created a number of output files in the directory where the file `dummy.dict` is located. You may remember from the start of this lesson that we loaded the dictionary with `%explore /tmp/dummy.dict`. The location of this file is what matters. The current working directory does not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "├── GaAs\n",
      "│   └── OUTCAR\n",
      "├── diamond\n",
      "│   ├── OUTCAR\n",
      "│   └── alloy\n",
      "│       └── OUTCAR\n",
      "├── dummy.dict\n",
      "└── jobA\n",
      "    └── OUTCAR\n",
      "\n",
      "4 directories, 5 files\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "[ ! -e tree ] || tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will notice that the job in `alloy/diamond` did not run since it is off. If you were to go back up a few cells and set it to `on`, and then rerun via `%launch interactive`, you should see that it will be computed. \n",
    "\n",
    "We can now navigate using %goto, simultaneously through the jobfolder and the disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current location:  /diamond/\n"
     ]
    }
   ],
   "source": [
    "%goto /diamond\n",
    "print(\"current location: \", jobparams.current.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "├── OUTCAR\n",
      "└── alloy\n",
      "    └── OUTCAR\n",
      "\n",
      "1 directory, 2 files\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "[ ! -e tree ] || tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting results\n",
    "\n",
    "The first thing one wants to know from calculations is whether they ran successfully:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  '/GaAs/':          True,\n",
       "  '/diamond/':       True,\n",
       "  '/diamond/alloy/': True,\n",
       "}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%goto /\n",
    "collect.success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dummy functional is too simple to fail... However, if you delete any given calculation directory, and try it again, you will find some false results. Beware that some collected results are cached so they can be retrieved faster the second time around, so redoing ``%explore some.dict`` might be necessary.\n",
    "\n",
    "**Warning** Success means that the calculations ran to completion. It does not mean that they are not garbage.\n",
    "\n",
    "Results from the calculation can be retrieved in much the same way as parameters were examined. This time, however, we use an object called ``collect`` (still without preceding \"%\" sign). Assuming the job-folders created earlier were launched, the random energies created by our fake functional could be retrieved as in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  '/GaAs/':          0.16078907235078244,\n",
       "  '/diamond/':       0.7704390379154654,\n",
       "  '/diamond/alloy/': 0.5635669216988963,\n",
       "}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect.energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What exactly can be collected this way will depend on the actual calculation. The easiest way to examine what's available it to hit `collect.[TAB]`. The collected results can be iterated over, focussed to a few relevant\n",
    "calculations, exactly as was done with `jobparams`. The advantage is that further job-folders can be easily constructed which take the calculations a bit further. For instance, we have created job-folders which minimize spin-polarized crystal structures. Then a second-wave of job-folders would be created from the resulting relaxed crystal structures to examine different possible magnetic orders.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
